{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-10.00, -55.00], zoom_start=4)\n",
    "\n",
    "brasil_edge = 'br_muns.geojson'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.GeoJson(\n",
    "    brasil_edge,\n",
    "    name='geojson'\n",
    ").add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset sample\n",
    "# The data to load\n",
    "\n",
    "# Count the lines\n",
    "num_lines = sum(1 for l in open('file2.csv'))\n",
    "\n",
    "# Sample size - in this case ~5%\n",
    "size = int(num_lines / 45)\n",
    "\n",
    "# The row indices to skip - make sure 0 is not included to keep the header!\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
    "\n",
    "# Read the \n",
    "packages = pd.read_csv('file2.csv', skiprows=skip_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset dimensions:', packages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns:\\n\\n', list(packages.columns))\n",
    "packages.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = ['deadline_time',\n",
    "                     'first_delivery_attempt_time',\n",
    "                     'crossdocking_arrival_time',\n",
    "                     'transfer_dispatch_time',\n",
    "                     'transfer_receival_time',\n",
    "                     'last_mile_allocation_start_time',\n",
    "                     'last_mile_driver_pickup_time']\n",
    "\n",
    "\n",
    "for columns in datetime_columns:\n",
    "    packages[columns] = pd.to_datetime(packages[columns], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "packages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "categorical_cols = ['agreed_slo','final_city','mesoregion', 'status']\n",
    "\n",
    "print('Categories per column:\\n')\n",
    "for column in categorical_cols:\n",
    "    print(column)\n",
    "    print('# of Categories: ', packages[column].nunique())\n",
    "    print('Categories: ',packages[column].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "id_cols = ['package_id','company_id']\n",
    "\n",
    "print('IDs per column:\\n')\n",
    "for column in id_cols:\n",
    "    print(column)\n",
    "    print('Amount of unique ID: ', packages[column].nunique())\n",
    "\n",
    "print('Over ', packages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_demanded_mesoregions = packages['mesoregion'].value_counts().head(30).index.tolist()\n",
    "most_demanded_mesoregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[packages['mesoregion'].map(lambda x: x in most_demanded_mesoregions)]['mesoregion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages[packages['mesoregion'].map(lambda x: x in most_demanded_mesoregions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data = packages[packages['mesoregion'].map(lambda x: x in most_demanded_mesoregions)]['mesoregion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brasil_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brasil_data = pd.read_csv('brazil_cities.csv')\n",
    "brasil_data.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brasil_data[brasil_data.duplicated(['city'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by first name \n",
    "brasil_data.sort_values(\"city\", inplace = True) \n",
    "  \n",
    "# making a bool series \n",
    "bool_series = brasil_data[\"city\"].duplicated(keep = False) \n",
    "  \n",
    "# bool series \n",
    "bool_series \n",
    "  \n",
    "# passing NOT of bool series to see unique values only \n",
    "new_brasil_data = brasil_data[~bool_series]\n",
    "  \n",
    "# displaying data \n",
    "new_brasil_data.info() \n",
    "new_brasil_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brasil_data[new_brasil_data['city'].str.startswith('B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = state_data.to_frame()\n",
    "\n",
    "df_new.reset_index(level=0, inplace=True)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.rename(columns={\"index\":\"city\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.sort_values(\"city\", inplace = True)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['lat']=0\n",
    "df_new['lng']=0\n",
    "\n",
    "df_cities = pd.DataFrame(columns=['city', 'mesoregion', 'lat', 'lng'])\n",
    "\n",
    "for ind in df_new.index:\n",
    "    exists =  df_new['city'][ind] in new_brasil_data['city'].values\n",
    "    if exists:\n",
    "        ciudad = df_new['city'][ind]\n",
    "        rslt_df = pd.DataFrame(new_brasil_data[new_brasil_data['city']==ciudad])\n",
    "\n",
    "        lat_temp = 0\n",
    "        lng_temp = 0\n",
    "        for index, value in rslt_df.lat.items():\n",
    "            lat_temp = value\n",
    "\n",
    "        for index, value in rslt_df.lng.items():\n",
    "            lng_temp = value\n",
    "\n",
    "        new_row=[{'city': ciudad, 'mesoregion':df_new['mesoregion'][ind], \n",
    "                 'lat':lat_temp, 'lng': lng_temp}]\n",
    "        \n",
    "        df_temp = pd.DataFrame(data=new_row, columns=['city', 'mesoregion', 'lat', 'lng'])\n",
    "        \n",
    "        df_cities = pd.concat([df_cities, df_temp], ignore_index=True)\n",
    "        \n",
    "print(df_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import plugins \n",
    "\n",
    "import branca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationArr = df_cities[['lat', 'lng']].values\n",
    "\n",
    "# plot heatmap\n",
    "m.add_child(plugins.HeatMap(stationArr, radius=25))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-10.00, -55.00], zoom_start=4)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=brasil_edge,\n",
    "    data=df_cities,\n",
    "    columns=['city', 'mesoregion'],\n",
    "    fill_color='YlGnBu',\n",
    "    fill_opacity=0.2,\n",
    "    line_opacity=1,\n",
    "    highlight=True,\n",
    "    smooth_factor=0,\n",
    "    legend_name='Packages'\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "world_choropelth = folium.Map(location=[-10.00, -55.00], tiles='Mapbox Bright',zoom_start=4)\n",
    "\n",
    "world_choropelth.choropleth(\n",
    "    geo_data=brasil_edge,\n",
    "    data=df_cities,\n",
    "    columns=['city','mesoregion'],\n",
    "    key_on='feature.properties.nome',\n",
    "    fill_color='YlOrRd',\n",
    "    fill_opacity=0.2, \n",
    "    line_opacity=1,\n",
    "    highlight=True,\n",
    "    smooth_factor=0,\n",
    "    \n",
    "    legend_name='Packages Delivered')\n",
    "\n",
    "folium.LayerControl().add_to(world_choropelth)\n",
    "# display map\n",
    "world_choropelth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
